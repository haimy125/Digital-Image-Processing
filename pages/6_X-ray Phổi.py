import streamlit as st
from PIL import Image, ImageOps
import torch
import torch.nn as nn
from torchvision import transforms

# Load model
class XRayCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1, 16, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64 * 28 * 28, 128), nn.ReLU(),
            nn.Linear(128, 2)
        )
    def forward(self, x): return self.net(x)

@st.cache_resource
def load_model():
    model = XRayCNN()
    model.load_state_dict(torch.load("models/xray_cnn_balanced_v2.pth", map_location=torch.device('cpu')))
    model.eval()
    return model

model = load_model()

# UI
st.title("ü´Å Ph√¢n lo·∫°i ·∫£nh X-ray ph·ªïi")
uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh X-ray", type=["jpg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("L")
    st.image(image, caption="·∫¢nh X-ray", use_container_width=True)

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ])
    img_tensor = transform(image).unsqueeze(0)

    output = model(img_tensor)
    _, pred = torch.max(output, 1)
    label = ["B√¨nh th∆∞·ªùng", "Vi√™m ph·ªïi"][pred.item()]
    st.success(f"K·∫øt qu·∫£: **{label}**")
    probs = torch.softmax(output, dim=1).squeeze().tolist()
    st.write(f"X√°c su·∫•t B√¨nh th∆∞·ªùng: {probs[0] * 100:.2f}%, Vi√™m ph·ªïi: {probs[1] * 100:.2f}%")

